program: finetune/main.py
method: grid
metric:
  goal: minimize
  name: eval/loss
parameters:
  id:
    value: ""
  mode:
    value: finetune
  model-name:
    values:
      - codellama/CodeLlama-7b-Python-hf
      - codellama/CodeLlama-7b-Instruct-hf
  dataset:
    values:
      - /home/djl328/prob-repl/datasets/wiz/hf-20:30k/NSCA
      - /home/djl328/prob-repl/datasets/wiz/hf-20:30k/NSE
      - /home/djl328/prob-repl/datasets/wiz/hf-20:30k/CA
      - /home/djl328/prob-repl/datasets/wiz/hf-20:30k/WW
      - /home/djl328/prob-repl/datasets/wiz/hf-20:30k/WD
  batch-size:
    value: 1
  max-seq-length:
    value: 1024
  epochs:
    value: 10
  lr-init:
    value: 5e-5                 # hf default
    # distribution: log_uniform_values
    # min: 1e-5
    # max: 1e-3
  lr-scheduler-type:
    values:
      - linear
      - cosine
      - constant
  kbit:
    values:
      - 4
      - 8
