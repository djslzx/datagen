program: dpp.py
method: random
metric:
  goal: maximize
  name: "mean knn dist"
parameters:
  mode:
    value: search
  domain:
    value: lsystem
  x_init:
    values:
      - - "20;F;F~F"
        - "90;F;F~FF"
        - "45;F[+F][-F]FF;F~FF"
        - "60;F+F-F;F~F+FF"
        - "60;F;F~F[+F][-F]F"
        - "90;F-F-F-F;F~F+FF-FF-F-F+F+FF-F-F+F+FF+FF-F"
        - "90;-F;F~F+F-F-F+F"
        - "90;F-F-F-F;F~FF-F-F-F-F-F+F"
        - "90;F-F-F-F;F~FF-F-F-F-FF"
        - "90;F-F-F-F;F~FF-F+F-F-FF"
        - "90;F-F-F-F;F~FF-F--F-F"
        - "90;F-F-F-F;F~F-FF--F-F"
        - "90;F-F-F-F;F~F-F+F-F-F"
        - "20;F;F~F[+F]F[-F]F"
        - "20;F;F~F[+F]F[-F][F]"
        - "20;F;F~FF-[-F+F+F]+[+F-F-F]"
  featurizer:
    parameters:
      disable_last_layer:
        value: true
      softmax_outputs:
        value: false
      sigma:
        value: 3
  render:
    parameters:
      step_length:
        value: 4
      render_depth:
        value: 3
      n_rows:
        value: 128
      n_cols:
        value: 128
      vary_color:
        value: false
  search:
    parameters:
      distance_metric:
        value: euclidean
      random_seed:
        value: 0
      popn_size:
        value: 1000
      epochs:
        value: 100
      update_policy:
        value: rr
      fit_policy:
        values: [ single, all, none, first ]
      accept_policy:
        values: [ energy, moment, all ]
      # archive_correction:
      #   values: [ true, false ]
      length_cap:
        value: 200
      keep_original:
        value: true
